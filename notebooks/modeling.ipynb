{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "This notebook will perform modeling of the `Improve` column of the Music Therapy Dataset. Models that will be tested include:\n",
    "- [Logistic Regression](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "- [Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "- [Gradient Boosting Classifier](https://scikit-learn.org/dev/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "The data has been cleaned and preprocessed, and saved as 'pre_processed_survey_results.csv.' All data is numeric, categorical variables have been encoded, and target feature `Improve` has been added. Data types, missingness, and columns will be validated before proceeding with modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ML Libraries\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ML Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random_state to be used throughout modeling for repeatability\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Hours per day</th>\n",
       "      <th>While working</th>\n",
       "      <th>Instrumentalist</th>\n",
       "      <th>Composer</th>\n",
       "      <th>Exploratory</th>\n",
       "      <th>Foreign languages</th>\n",
       "      <th>BPM</th>\n",
       "      <th>Frequency [Classical]</th>\n",
       "      <th>Frequency [Country]</th>\n",
       "      <th>...</th>\n",
       "      <th>fav_Jazz</th>\n",
       "      <th>fav_K pop</th>\n",
       "      <th>fav_Latin</th>\n",
       "      <th>fav_Lofi</th>\n",
       "      <th>fav_Metal</th>\n",
       "      <th>fav_Pop</th>\n",
       "      <th>fav_R&amp;B</th>\n",
       "      <th>fav_Rap</th>\n",
       "      <th>fav_Rock</th>\n",
       "      <th>fav_Video game music</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Hours per day  While working  Instrumentalist  Composer  Exploratory  \\\n",
       "0   18            4.0              0                0         0            0   \n",
       "1   61            2.5              1                0         1            1   \n",
       "2   18            4.0              1                0         0            1   \n",
       "3   18            5.0              1                1         1            1   \n",
       "4   18            3.0              1                1         0            1   \n",
       "\n",
       "   Foreign languages    BPM  Frequency [Classical]  Frequency [Country]  ...  \\\n",
       "0                  1  132.0                      0                    0  ...   \n",
       "1                  1   84.0                      2                    0  ...   \n",
       "2                  0  107.0                      0                    0  ...   \n",
       "3                  1   86.0                      1                    2  ...   \n",
       "4                  1   66.0                      2                    0  ...   \n",
       "\n",
       "   fav_Jazz  fav_K pop  fav_Latin  fav_Lofi  fav_Metal  fav_Pop  fav_R&B  \\\n",
       "0         0          0          0         0          0        0        0   \n",
       "1         1          0          0         0          0        0        0   \n",
       "2         0          0          0         0          0        0        1   \n",
       "3         1          0          0         0          0        0        0   \n",
       "4         0          0          0         0          0        0        0   \n",
       "\n",
       "   fav_Rap  fav_Rock  fav_Video game music  \n",
       "0        0         0                     1  \n",
       "1        0         0                     0  \n",
       "2        0         0                     0  \n",
       "3        0         0                     0  \n",
       "4        0         0                     1  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data and investigate first 5 rows\n",
    "\n",
    "data = pd.read_csv('./../data/processed/pre_processed_survey_results.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Hours per day', 'While working', 'Instrumentalist', 'Composer',\n",
       "       'Exploratory', 'Foreign languages', 'BPM', 'Frequency [Classical]',\n",
       "       'Frequency [Country]', 'Frequency [EDM]', 'Frequency [Folk]',\n",
       "       'Frequency [Gospel]', 'Frequency [Hip hop]', 'Frequency [Jazz]',\n",
       "       'Frequency [K pop]', 'Frequency [Latin]', 'Frequency [Lofi]',\n",
       "       'Frequency [Metal]', 'Frequency [Pop]', 'Frequency [R&B]',\n",
       "       'Frequency [Rap]', 'Frequency [Rock]', 'Frequency [Video game music]',\n",
       "       'Anxiety', 'Depression', 'Insomnia', 'OCD', 'Improve', 'No effect',\n",
       "       'Worsen', 'fav_Country', 'fav_EDM', 'fav_Folk', 'fav_Gospel',\n",
       "       'fav_Hip hop', 'fav_Jazz', 'fav_K pop', 'fav_Latin', 'fav_Lofi',\n",
       "       'fav_Metal', 'fav_Pop', 'fav_R&B', 'fav_Rap', 'fav_Rock',\n",
       "       'fav_Video game music'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check columns\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                               int64\n",
       "Hours per day                   float64\n",
       "While working                     int64\n",
       "Instrumentalist                   int64\n",
       "Composer                          int64\n",
       "Exploratory                       int64\n",
       "Foreign languages                 int64\n",
       "BPM                             float64\n",
       "Frequency [Classical]             int64\n",
       "Frequency [Country]               int64\n",
       "Frequency [EDM]                   int64\n",
       "Frequency [Folk]                  int64\n",
       "Frequency [Gospel]                int64\n",
       "Frequency [Hip hop]               int64\n",
       "Frequency [Jazz]                  int64\n",
       "Frequency [K pop]                 int64\n",
       "Frequency [Latin]                 int64\n",
       "Frequency [Lofi]                  int64\n",
       "Frequency [Metal]                 int64\n",
       "Frequency [Pop]                   int64\n",
       "Frequency [R&B]                   int64\n",
       "Frequency [Rap]                   int64\n",
       "Frequency [Rock]                  int64\n",
       "Frequency [Video game music]      int64\n",
       "Anxiety                           int64\n",
       "Depression                        int64\n",
       "Insomnia                          int64\n",
       "OCD                               int64\n",
       "Improve                           int64\n",
       "No effect                         int64\n",
       "Worsen                            int64\n",
       "fav_Country                       int64\n",
       "fav_EDM                           int64\n",
       "fav_Folk                          int64\n",
       "fav_Gospel                        int64\n",
       "fav_Hip hop                       int64\n",
       "fav_Jazz                          int64\n",
       "fav_K pop                         int64\n",
       "fav_Latin                         int64\n",
       "fav_Lofi                          int64\n",
       "fav_Metal                         int64\n",
       "fav_Pop                           int64\n",
       "fav_R&B                           int64\n",
       "fav_Rap                           int64\n",
       "fav_Rock                          int64\n",
       "fav_Video game music              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check datatypes\n",
    "\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                             0\n",
       "Hours per day                   0\n",
       "While working                   0\n",
       "Instrumentalist                 0\n",
       "Composer                        0\n",
       "Exploratory                     0\n",
       "Foreign languages               0\n",
       "BPM                             0\n",
       "Frequency [Classical]           0\n",
       "Frequency [Country]             0\n",
       "Frequency [EDM]                 0\n",
       "Frequency [Folk]                0\n",
       "Frequency [Gospel]              0\n",
       "Frequency [Hip hop]             0\n",
       "Frequency [Jazz]                0\n",
       "Frequency [K pop]               0\n",
       "Frequency [Latin]               0\n",
       "Frequency [Lofi]                0\n",
       "Frequency [Metal]               0\n",
       "Frequency [Pop]                 0\n",
       "Frequency [R&B]                 0\n",
       "Frequency [Rap]                 0\n",
       "Frequency [Rock]                0\n",
       "Frequency [Video game music]    0\n",
       "Anxiety                         0\n",
       "Depression                      0\n",
       "Insomnia                        0\n",
       "OCD                             0\n",
       "Improve                         0\n",
       "No effect                       0\n",
       "Worsen                          0\n",
       "fav_Country                     0\n",
       "fav_EDM                         0\n",
       "fav_Folk                        0\n",
       "fav_Gospel                      0\n",
       "fav_Hip hop                     0\n",
       "fav_Jazz                        0\n",
       "fav_K pop                       0\n",
       "fav_Latin                       0\n",
       "fav_Lofi                        0\n",
       "fav_Metal                       0\n",
       "fav_Pop                         0\n",
       "fav_R&B                         0\n",
       "fav_Rap                         0\n",
       "fav_Rock                        0\n",
       "fav_Video game music            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `Improve`, `No effect`, and `Worsen` are collinear, `Worsen` will be dropped. Otherwise combination of the three would be able to perfectly predict `Improve`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Drop Worsen column\n",
    "\n",
    "data = data.drop('Worsen', axis=1)\n",
    "\n",
    "print('Worsen' in data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data\n",
    "\n",
    "Data will be split into `X` and `y`, where `y` is the `Improve` column and `X` is the rest of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y, then training and testing\n",
    "\n",
    "X = data.drop('Improve', axis=1)\n",
    "y = data['Improve']\n",
    "\n",
    "# Split into training and testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Before comparing the results of our three models, we'll perform some hyperparameter tuning to generate the best models for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up scaling for continuous variables\n",
    "\n",
    "numeric_cols = ['Age', 'BPM', 'Hours per day']\n",
    "preprocesser = ColumnTransformer(transformers = [('numeric', StandardScaler(), numeric_cols)])\n",
    "\n",
    "# Set up KFold for cross-validation\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score: 0.85\n",
      "Best parameters: {'classifier__C': 0.4444444444444444, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "225 fits failed out of a total of 450.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'C' parameter of LogisticRegression must be a float in the range (0, inf]. Got 0.0 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "                         ~~^~~~~~~~~~\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/arsen/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.85430176 0.85430176 0.85430176        nan 0.85430176 0.85430176\n",
      "        nan        nan        nan 0.85430176 0.85430176 0.85430176\n",
      "        nan 0.85430176 0.85430176        nan        nan        nan\n",
      " 0.85430176 0.85430176 0.85430176        nan 0.85430176 0.85430176\n",
      "        nan        nan        nan 0.85430176 0.85430176 0.85430176\n",
      "        nan 0.85430176 0.85430176        nan        nan        nan\n",
      " 0.85430176 0.85430176 0.85430176        nan 0.85430176 0.85430176\n",
      "        nan        nan        nan 0.85430176 0.85430176 0.85430176\n",
      "        nan 0.85430176 0.85430176        nan        nan        nan\n",
      " 0.85430176 0.85430176 0.85430176        nan 0.85430176 0.85430176\n",
      "        nan        nan        nan 0.85430176 0.85430176 0.85430176\n",
      "        nan 0.85430176 0.85430176        nan        nan        nan\n",
      " 0.85430176 0.85430176 0.85430176        nan 0.85430176 0.85430176]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set up pipeline\n",
    "\n",
    "steps = [\n",
    "    ('preprocessor', preprocesser),\n",
    "    ('classifier', LogisticRegression(max_iter=3000))\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Set up hyperparameter tuning parameters\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__penalty' : ['elasticnet', 'l2', 'l1'],\n",
    "    'classifier__C' : np.linspace(0, 4, 10),\n",
    "    'classifier__solver' : ['lbfgs', 'liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "lr_cv = GridSearchCV(pipeline, param_grid, cv=kf, scoring='f1', n_jobs=-1)\n",
    "lr_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print results\n",
    "\n",
    "print(f\"Mean accuracy score: {round(lr_cv.best_score_, 2)}\")\n",
    "print(f\"Best parameters: {lr_cv.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the logistic regression model, the best parameters are: 'C': 0.08163265306122448, 'penalty': 'l2', 'solver': 'lbfgs'. These yielded a mean f1-score of 0.85. We used f1-score to measure the performance of our model because we have imbalanced classes and accuracy would not be a good metric to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score: 0.85\n",
      "Best parameters: {'classifier__n_estimators': 786, 'classifier__min_samples_split': 7, 'classifier__min_samples_leaf': 9, 'classifier__min_impurity_decrease': 0.022222222222222223, 'classifier__max_depth': 33, 'classifier__criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "# Set up pipeline\n",
    "\n",
    "steps = [\n",
    "    ('preprocessor', preprocesser),\n",
    "    ('classifier', RandomForestClassifier(random_state=RANDOM_STATE))\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Set up hyperparameter tuning parameters\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators' : np.arange(200,1000),\n",
    "    'classifier__criterion' : ['gini', 'entropy', 'log_loss'],\n",
    "    'classifier__max_depth' : np.arange(5,100),\n",
    "    'classifier__min_samples_split' : np.arange(2,10),\n",
    "    'classifier__min_samples_leaf' : np.arange(2,10),\n",
    "    'classifier__min_impurity_decrease' : np.linspace(0, 0.1, 10)\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "rf_cv = RandomizedSearchCV(pipeline, param_grid, cv=kf, scoring='f1', n_jobs=-1)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print results\n",
    "\n",
    "print(f\"Mean accuracy score: {round(rf_cv.best_score_, 2)}\")\n",
    "print(f\"Best parameters: {rf_cv.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score: 0.86\n",
      "Best parameters: {'classifier__n_estimators': 634, 'classifier__min_samples_split': 1.0, 'classifier__min_impurity_decrease': 0.011111111111111112, 'classifier__loss': 'exponential', 'classifier__learning_rate': 0.023000000000000003, 'classifier__criterion': 'friedman_mse'}\n"
     ]
    }
   ],
   "source": [
    "# Set up pipeline\n",
    "\n",
    "steps = [\n",
    "    ('preprocessor', preprocesser),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=RANDOM_STATE))\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Set up hyperparameter tuning parameters\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators' : np.arange(200,1000),\n",
    "    'classifier__loss' : ['log_loss', 'exponential'],\n",
    "    'classifier__learning_rate' : np.linspace(0.001, 0.1, 10),\n",
    "    'classifier__criterion' : ['friedman_mse', 'squared_error'],\n",
    "    'classifier__min_samples_split' : np.linspace(0,1, 10),\n",
    "    'classifier__min_impurity_decrease' : np.linspace(0, 0.1, 10)\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "gbc_cv = RandomizedSearchCV(pipeline, param_grid, cv=kf, scoring='f1', n_jobs=-1)\n",
    "gbc_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print results\n",
    "\n",
    "print(f\"Mean accuracy score: {round(gbc_cv.best_score_, 2)}\")\n",
    "print(f\"Best parameters: {gbc_cv.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "Now that we have three models with tuned hyperparameters, we'll compare their abilities to predict the test data in order to select the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.7407407407407407\n",
      "Random Forest Classifier : 0.7407407407407407\n",
      "Gradient Boosting Classifier : 0.75\n"
     ]
    }
   ],
   "source": [
    "# List best models as determined by hyperparameter tuning\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression' : lr_cv.best_estimator_,\n",
    "    'Random Forest Classifier' : rf_cv.best_estimator_,\n",
    "    'Gradient Boosting Classifier' : gbc_cv.best_estimator_\n",
    "}\n",
    "\n",
    "# Loop through models and score based on test data\n",
    "\n",
    "model_scores = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"{name} : {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
